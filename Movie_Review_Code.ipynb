{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDkysE6StRZmftZ3F3dwDF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/warrengmartin/Which-Movie-For-Me/blob/main/Movie_Review_Code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# URLs for the MovieLens dataset\n",
        "ratings_url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
        "\n",
        "# Download the dataset\n",
        "response = requests.get(ratings_url)\n",
        "zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
        "\n",
        "# Extract the ratings.csv and movies.csv files\n",
        "zip_file.extract('ml-latest-small/ratings.csv', '.')\n",
        "zip_file.extract('ml-latest-small/movies.csv', '.')\n",
        "\n",
        "# Rename the extracted files to remove the directory prefix\n",
        "os.rename('ml-latest-small/ratings.csv', 'ratings.csv')\n",
        "os.rename('ml-latest-small/movies.csv', 'movies.csv')\n",
        "\n",
        "print(\"Files downloaded and extracted successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAceDP1PG9T0",
        "outputId": "df4238bd-0f2f-4833-a48a-e28e40c770c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files downloaded and extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Load the MovieLens dataset\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "movies = pd.read_csv('movies.csv')\n",
        "\n",
        "# Merge ratings and movies on movieId\n",
        "data = pd.merge(ratings, movies, on='movieId')\n",
        "\n",
        "# Create a user-item interaction matrix\n",
        "user_item_matrix = data.pivot_table(index='userId', columns='movieId', values='rating')\n",
        "\n",
        "# # Fill NaN values with 0\n",
        "# user_item_matrix = user_item_matrix.fillna(0)\n",
        "\n",
        "\n",
        "imputer = KNNImputer(n_neighbors=2)\n",
        "user_item_matrix_imputed = imputer.fit_transform(user_item_matrix)  # Store imputed data in a new variable\n",
        "\n",
        "# Convert the imputed NumPy array back to a Pandas DataFrame\n",
        "user_item_matrix = pd.DataFrame(user_item_matrix_imputed,\n",
        "                                 index=user_item_matrix.index,  # Use original DataFrame's index\n",
        "                                 columns=user_item_matrix.columns) # Use original DataFrame's columns"
      ],
      "metadata": {
        "id": "dyHAK-KePJZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Normalize the ratings (changed to min-max normalization)\n",
        "user_item_matrix_norm = (user_item_matrix - user_item_matrix.min().min()) / (user_item_matrix.max().max() - user_item_matrix.min().min())\n",
        "\n",
        "# Convert to a PyTorch tensor\n",
        "user_item_tensor = torch.tensor(user_item_matrix_norm.values, dtype=torch.float)\n",
        "\n",
        "# Define the dataset class\n",
        "class MovieLensDataset(Dataset):\n",
        "    def __init__(self, user_item_tensor):\n",
        "        self.user_item_tensor = user_item_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.user_item_tensor.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.user_item_tensor[idx]\n",
        "\n",
        "# Create the dataset and dataloader\n",
        "dataset = MovieLensDataset(user_item_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "# Define the model\n",
        "class CollaborativeFiltering(nn.Module):\n",
        "    def __init__(self, num_users, num_items, embedding_dim):\n",
        "        super(CollaborativeFiltering, self).__init__()\n",
        "        self.user_embedding = nn.Embedding(num_users + 1, embedding_dim)  # +1 for new users\n",
        "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
        "        self.fc = nn.Linear(embedding_dim, 1)\n",
        "\n",
        "        # Initialize embeddings\n",
        "        nn.init.normal_(self.user_embedding.weight, mean=0, std=0.01)\n",
        "        nn.init.normal_(self.item_embedding.weight, mean=0, std=0.01)\n",
        "\n",
        "    def forward(self, user_indices, item_indices):\n",
        "        user_embed = self.user_embedding(user_indices)\n",
        "        item_embed = self.item_embedding(item_indices)\n",
        "        x = torch.mul(user_embed, item_embed)\n",
        "        x = torch.sum(x, dim=-1)\n",
        "        return torch.sigmoid(x)  # Apply sigmoid to bound output between 0 and 1\n",
        "\n",
        "    def predict_new_user(self, new_user_vector, item_indices):\n",
        "        new_user_embed = torch.matmul(new_user_vector, self.item_embedding.weight)\n",
        "        item_embed = self.item_embedding(item_indices)\n",
        "        x = torch.mul(new_user_embed, item_embed)\n",
        "        x = torch.sum(x, dim=-1)\n",
        "        return torch.sigmoid(x)\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "num_users = user_item_matrix.shape[0]\n",
        "num_items = user_item_matrix.shape[1]\n",
        "embedding_dim = 50\n",
        "model = CollaborativeFiltering(num_users, num_items, embedding_dim)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)  # Reduced learning rate\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        batch_size = batch.shape[0]\n",
        "        num_items = batch.shape[1]\n",
        "\n",
        "        # Create user and item indices for the batch\n",
        "        user_indices = torch.arange(batch_size).unsqueeze(1).expand(-1, num_items)\n",
        "        item_indices = torch.arange(num_items).unsqueeze(0).expand(batch_size, -1)\n",
        "\n",
        "        ratings = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(user_indices, item_indices)\n",
        "        loss = criterion(predictions, ratings)\n",
        "\n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {total_loss/len(dataloader)}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    user_indices = torch.arange(user_item_matrix.shape[0]).unsqueeze(1).expand(-1, user_item_matrix.shape[1])\n",
        "    item_indices = torch.arange(user_item_matrix.shape[1]).unsqueeze(0).expand(user_item_matrix.shape[0], -1)\n",
        "    predictions = model(user_indices, item_indices)\n",
        "    mse = criterion(predictions, user_item_tensor)\n",
        "    print(f'Validation MSE: {mse.item()}')\n",
        "\n",
        "torch.save(model.state_dict(), 'collaborative_filtering_model.pth')\n",
        "print(\"Model saved successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi2O2gpiG05V",
        "outputId": "b3c87443-9ff3-4626-dbd8-cfec963d7ed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 0.03833123194053769\n",
            "Epoch 2/3, Loss: 0.009790681838057935\n",
            "Epoch 3/3, Loss: 0.007615978247486055\n",
            "Validation MSE: 0.05733146145939827\n",
            "Model saved successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_and_predict(new_user_ratings, user_item_matrix, model_path):\n",
        "    # Load the model\n",
        "    model = CollaborativeFiltering(user_item_matrix.shape[0], user_item_matrix.shape[1], embedding_dim)\n",
        "    model.load_state_dict(torch.load(model_path))\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare the new user's ratings\n",
        "    new_user_vector = pd.Series(index=user_item_matrix.columns, dtype=float)\n",
        "    new_user_vector.loc[new_user_ratings.index] = new_user_ratings['rating']\n",
        "    new_user_vector = new_user_vector.fillna(0)\n",
        "\n",
        "    # Normalize the new user's ratings\n",
        "    new_user_vector_norm = (new_user_vector - user_item_matrix.min().min()) / (user_item_matrix.max().max() - user_item_matrix.min().min())\n",
        "\n",
        "    # Convert to tensor\n",
        "    new_user_tensor = torch.tensor(new_user_vector_norm.values, dtype=torch.float).unsqueeze(0)\n",
        "\n",
        "    # Make predictions\n",
        "    with torch.no_grad():\n",
        "        item_indices = torch.arange(user_item_matrix.shape[1])\n",
        "        predictions = model.predict_new_user(new_user_tensor, item_indices)\n",
        "\n",
        "    # Convert predictions to DataFrame\n",
        "    predicted_ratings = pd.Series(predictions.squeeze().numpy(), index=user_item_matrix.columns)\n",
        "\n",
        "    return predicted_ratings"
      ],
      "metadata": {
        "id": "ezi3_C9_NDU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Generate new user ratings (at least 5 ratings)\n",
        "np.random.seed(123)  # for reproducibility\n",
        "num_ratings = 5000  # You can change this to any number >= 5\n",
        "random_movies = np.random.choice(user_item_matrix.columns, num_ratings, replace=False)\n",
        "new_user_ratings = pd.DataFrame({\n",
        "    'movieId': random_movies,\n",
        "    'rating': np.random.randint(0, 4, size=num_ratings)  # Ratings from 1 to 5\n",
        "}).set_index('movieId')\n",
        "\n",
        "\n",
        "print(\"New user ratings:\")\n",
        "print(new_user_ratings.head())\n",
        "\n",
        "# Load the model and make predictions\n",
        "predicted_ratings = load_model_and_predict(new_user_ratings, user_item_matrix, 'collaborative_filtering_model.pth')\n",
        "\n",
        "# Sort and display top 10 recommended movies\n",
        "top_10_recommendations = predicted_ratings.sort_values(ascending=False).head(5)\n",
        "recommended_movies = movies[movies['movieId'].isin(top_10_recommendations.index)]\n",
        "\n",
        "print(\"\\nTop 5 movie recommendations for the new user:\")\n",
        "print(recommended_movies[['title', 'genres']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qotoCo5BKBZe",
        "outputId": "d45bf688-7257-4fcd-cc5c-0d527ab23450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New user ratings:\n",
            "         rating\n",
            "movieId        \n",
            "31692         1\n",
            "4814          0\n",
            "88272         2\n",
            "47721         0\n",
            "6347          3\n",
            "\n",
            "Top 5 movie recommendations for the new user:\n",
            "                                      title  \\\n",
            "0                          Toy Story (1995)   \n",
            "6020              Darwin's Nightmare (2004)   \n",
            "6022    No Direction Home: Bob Dylan (2005)   \n",
            "6023  Goal! The Dream Begins (Goal!) (2005)   \n",
            "6026        Squid and the Whale, The (2005)   \n",
            "\n",
            "                                           genres  \n",
            "0     Adventure|Animation|Children|Comedy|Fantasy  \n",
            "6020                                  Documentary  \n",
            "6022                                  Documentary  \n",
            "6023                                        Drama  \n",
            "6026                                 Comedy|Drama  \n"
          ]
        }
      ]
    }
  ]
}